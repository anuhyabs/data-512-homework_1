{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA ACQUISITION\n",
    "\n",
    "In this notebook, the data on counts of pageviews from desktop, mobile web and mobile app is collected for a subset of English Wikipedia dinosaur related articles.\n",
    "\n",
    "The output of the notebook are three datasets saved as JSON files ordered using article titles as a key for the resulting time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json, time, urllib.parse\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The REST API 'pageviews' URL - this is the common URL/endpoint for all 'pageviews' API requests\n",
    "API_REQUEST_PAGEVIEWS_ENDPOINT = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/'\n",
    "\n",
    "# This is a parameterized string that specifies what kind of pageviews request we are going to make\n",
    "# In this case it will be a 'per-article' based request. The string is a format string so that we can\n",
    "# replace each parameter with an appropriate value before making the request\n",
    "API_REQUEST_PER_ARTICLE_PARAMS = 'per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}'\n",
    "\n",
    "# The Pageviews API asks that we not exceed 100 requests per second, we add a small delay to each request\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making a request to the Wikimedia API they ask that you include a \"unique ID\" that will allow them to\n",
    "# contact you if something happens - such as - your code exceeding request limits - or some other error happens\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<anuhyabs@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2022',\n",
    "}\n",
    "\n",
    "# This is a subset of the English Wikipedia dinosaur related files.\n",
    "ARTICLE_TITLES = pd.read_csv('dinosaur_genera.cleaned.SEPT.2022.csv')[\"name\"]\n",
    "START_DATE = \"2015010100\"\n",
    "END_DATE = \"2022093000\"\n",
    "\n",
    "DESKTOP_DATA = \"dino_monthly_desktop_201501-202209.json\"\n",
    "MOBILE_DATA = \"dino_monthly_mobile_201501-202209.json\"\n",
    "CUMULATIVE_DATA = \"dino_monthly_cumulative_201501-202209.json\" \n",
    "\n",
    "# This template is used to map parameter values into the API_REQUST_PER_ARTICLE_PARAMS portion of an API request. The dictionary has a\n",
    "# field/key for each of the required parameters. \n",
    "ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"\",      # this value will be changed for the different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       START_DATE,\n",
    "    \"end\":         END_DATE   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_pageviews_per_article(article_title = None, \n",
    "                                  access = \"desktop\",\n",
    "                                  endpoint_url = API_REQUEST_PAGEVIEWS_ENDPOINT, \n",
    "                                  endpoint_params = API_REQUEST_PER_ARTICLE_PARAMS, \n",
    "                                  request_template = ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE,\n",
    "                                  headers = REQUEST_HEADERS):\n",
    "    # Make sure we have an article title\n",
    "    if not article_title: return None\n",
    "    \n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    article_title_encoded = urllib.parse.quote(article_title.replace(' ','_'))\n",
    "    request_template['article'] = article_title_encoded\n",
    "    request_template['access'] = access\n",
    "\n",
    "    \n",
    "    # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A general function to generate datasets for all articles at different access levels\n",
    "def generate_views(articles, access):\n",
    "    views_json = {}\n",
    "\n",
    "    if access == \"mobile\":\n",
    "        # The API separates mobile access types into two separate requests: mobile-app and mobile-web.\n",
    "        # The following code sums these to make one count for all mobile pageviews.\n",
    "        mobile_views = {}\n",
    "        for title in articles:\n",
    "            mobile_app_views = request_pageviews_per_article(title, \"mobile-app\")\n",
    "            mobile_web_views = request_pageviews_per_article(title, \"mobile-web\")\n",
    "        \n",
    "            mobile_app_views = mobile_app_views['items']\n",
    "            mobile_web_views = mobile_web_views['items']\n",
    "            mobile_views = mobile_app_views\n",
    "            for month in range(len(mobile_web_views)):\n",
    "                mon = mobile_web_views[month]\n",
    "                views = mon['views']\n",
    "                mobile_views[month]['views'] += views\n",
    "            views_json[title] = mobile_views\n",
    "    else:        \n",
    "        for title in articles:\n",
    "            views = request_pageviews_per_article(title, access)\n",
    "            views = views['items']\n",
    "            views_json[title] = views\n",
    "\n",
    "    return views_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the datasets as JSON files\n",
    "def write_file(path, views):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(views, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating monthly desktop views\n",
    "desktop_views = generate_views(ARTICLE_TITLES, \"desktop\")\n",
    "write_file(DESKTOP_DATA, desktop_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating monthly cumulative views\n",
    "cumulative_views = generate_views(ARTICLE_TITLES, \"all-access\")\n",
    "write_file(CUMULATIVE_DATA, cumulative_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating monthly mobile views\n",
    "mobile_views = generate_views(ARTICLE_TITLES, \"mobile\")\n",
    "write_file(MOBILE_DATA, mobile_views)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7019494c316389886f5f5fcb2e396e2fee403f1eb1d04a04c662a640ad80dd4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
